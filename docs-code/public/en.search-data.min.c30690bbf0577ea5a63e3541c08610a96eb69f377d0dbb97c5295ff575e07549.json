[{"id":0,"href":"/BenchPilot/docs/getting-started/","title":"Getting Started","section":"Docs","content":" BenchPilot # BenchPilot: Repeatable \u0026amp; Reproducible Benchmarking for Edge Micro-DCs\nBenchPilot is a modular and highly customizable benchmarking framework for edge micro-DCs. BenchPilot provides a high-level declarative model for describing experiment testbeds and scenarios that automates the benchmarking process using various workloads. The latter enables users to focus on performance analysis instead of dealing with the complex and time-consuming setup. BenchPilot instantiates the underlying cluster, performs repeatable experimentation, and provides a unified monitoring stack in heterogeneous Micro-DCs.\nExperiment Setup # A typical workflow starts with the user submitting in a yaml file their choice of experiments, along with their selected workloads and their specific parameters. The BenchPilot model is composed with Experiments, where each Experiment has its own Workload descriptions. More information regarding the experiment setup can be found here.\nDeployment # When the description is ready, the user deploys the experiments using the BenchPilotSDK through a Jupyter notebook or a simple python script. If there\u0026rsquo;s no validation error from the description, the Parser will parse each experiment one-by-one and its preferences to the BenchPilot Deployment Template Generator, where the preferences will be transformed into docker-compose templates. At last, the Deployment Coordinator will deploy each experiment to the underlying orchestrator and closely monitor its performance through the monitoring stack. At the beginning and end of each experiment, the Coordinator records the starting/ending timestamps, so that the user can retrieve the monitored information later on.\nMonitoring # For extracting various infrastructure utilization metrics, including CPU, Memory, Network and Power Utilization, BenchPilot offers a transparent, from the application under test, monitoring stack. To achieve this, BenchPilot, in the bootstrapping stage, instantiates a containerized monitoring agent on every node. The agent inspects system information (e.g., performance pseudofiles and cgroup files) and extracts the required metrics in a non-intrusive way. The agent starts various probes, one for each sub-component (e.g., cgroup probe, OS probe, etc.), and exposes an API through which a centralized monitoring server retrieves the data periodically and stores them to the monitoring storage. Furthermore, the monitoring agent offers probes for external resources as well. From the implementation perspective, we have selected Netdata, a widely known and used monitoring tool, and Prometheus, an open-source and popular monitoring server, for our stack. For a monitoring storage backend, InfluxDB is used.\nPost-Experiment Analysis # To create an end-to-end interactive analytic tool for benchmarking, BenchPilot utilizes the Jupyter Notebook stack. Specifically, after the experimentation process is over, the user can request the monitored metrics of each execution from the monitoring storage based on the provided experiments\u0026rsquo; starting/ending timestamps. Users can apply high-level analytic models to the retrieved metrics of each experiment and have a clear overview of their deployments.\nWorkload List # As for now BenchPilot only supports the following containerized workloads:\nName Description marketing-campaign A streaming distributed workload that features an application as a data processing pipeline with multiple and diverse steps that emulate insight extraction from marketing campaigns. The workload utilizes technologies such as Kafka and Redis. mlperf An inference workload, that includes tasks such as image classification and object recognition. db A nosql database workload that keeps executing CRUD operations (Create, Read, Update and Delete). simple This workload represents simple stressors that target a specific resource to stress. Underneath uses the linux command stress or IPerf3. You can find more information for each workload here. It\u0026rsquo;s important to note that BenchPilot can be easily extended to add new workloads.\nResources # The Team # The creators of the BenchPilot are members of the Laboratory for Internet Computing (LInC), University of Cyprus. You can find more information about our research activity visit our publications\u0026rsquo; page and our on-going projects.\nAcknowledgements # This work is partially supported by the EU Commission through RAINBOW 871403 (ICT-15-2019-2020) project and by the Cyprus Research and Innovation Foundation through COMPLEMENTARY/0916/0916/0171 project, and from RAIS (Real-time analytics for the Internet of Sports), Marie Sk≈Çodowska-Curie Innovative Training Networks (ITN), under grant agreement No 813162.\nLicense # The framework is open-sourced under the Apache 2.0 License base. The codebase of the framework is maintained by the authors for academic research and is therefore provided \u0026ldquo;as is\u0026rdquo;.\nStart experimenting by installing Benchpilot now!\n"},{"id":1,"href":"/BenchPilot/docs/installation/","title":"Installation","section":"Docs","content":" GitHub Repository # Visit our Github Repository to download or fork BenchPilot!\nDockerHub # All of our Docker images are uploaded on our DockerHub Repository!\nBenchPilot Bootstrapping # Install Docker \u0026amp; Docker Compose # In the \u0026lsquo;Getting Started\u0026rsquo; section we learned how BenchPilot is structured. In order to use the BenchPilot client you need to have installed docker \u0026amp; docker-compose. In our GitHub Repository, under the /utils folder we have prepared for you a script to automatically download it, so all you need to run is \u0026ldquo;sh install-docker.sh\u0026rdquo;, which is under the monitoring folder.\nRetrieve or Build BenchPilot Client Image # The second step is to either retrieve or build the BenchPilot client image.\nPulling Image from DockerHub # For your ease, you can only pull the image from DockerHub just by running \u0026ldquo;docker pull benchpilot/benchpilot:client\u0026rdquo;.\nBuilding Image Locally # If you want to build the image locally, you firstly need to download or clone our GitHub repository, go under the benchpilot-sdk folder, and then execute the building image script by running the command \u0026ldquo;sh build-image.sh\u0026rdquo;.\nStart BenchPilot Client and start experimenting! # The final step is to just execute the following docker-compose.yaml by running the simple command \u0026ldquo;docker-compose up\u0026rdquo;. It is not needed from you to be familiarized with docker and docker-compose, but in case you want to learn more, you can always visit their website!\nversion: \u0026#39;3.8\u0026#39; # change it accordingly to your docker-compose version services: benchpilot: # if you chose to build it locally replace the it with: bench-pilot image: benchpilot/benchpilot:client volumes: - /var/run/docker.sock:/var/run/docker.sock - /usr/bin/docker:/usr/bin/docker ports: - 8888:8888 # port needed for jupyter environment: # define http(s)_proxy only if your devide is placed behind a proxy - http_proxy=${http_proxy} - https_proxy=${https_proxy} # jupyter environment variables - \u0026#34;JUPYTER_ENABLE_LAB=yes\u0026#34; - \u0026#34;GRANT_SUDO=yes\u0026#34; - \u0026#34;CHOWN_HOME=yes\u0026#34; # Prometheus environment variables - PROMETHEUS_IP=0.0.0.0 - PROMETHEUS_PREFIX=${your_datacenter_prefix} user: root After starting the BenchPilot client, you can access jupyter through your browser from this link: \u0026ldquo;http://your_device_ip:8888\u0026rdquo;, and start experimenting!\nLearn how to define your experiments here.\n"},{"id":2,"href":"/BenchPilot/docs/experiments/","title":"Experiments","section":"Docs","content":" Experiments # Before starting the benchmarking process, you need to define (i) the cluster under test, and (ii) the experiments you want to perform.\nDefining your Cluster # By defining you cluster, Benchpilot removes the effort of you needing to download docker, docker compose and every docker image you may need for your benchmarking on your worker devices. All you need to do is define your cluster inside the /BenchPilotSDK/conf/bench-cluster.yaml.\nInside the \u0026ldquo;bench-cluster.yaml\u0026rdquo; we define our cluster nodes. So as we can see below, we define our cluster with the keywoard \u0026ldquo;cluster\u0026rdquo;, and afterwards we define the manager, where the benchpilot client will be deployed on, and the nodes that are represented as workers.\nFor all nodes, it is needed to define their ip, and proxy - if needed, and for each worker it\u0026rsquo;s required to define their hostname, and authentication credentials. These credentials include the username, and password or the path to an ssh key.\ncluster: manager: ip: \u0026#34;0.0.0.0\u0026#34; # assign the IP of the device that will run the benchpilot client # in case of not using a proxy - remove the following 3 lines proxies: http_proxy: \u0026#34;http://example.proxy.com:8080/\u0026#34; https_proxy: \u0026#34;https://example.proxy.com:8080/\u0026#34; nodes: # here define the nodes that you will benchmark - ip: \u0026#34;10.10.10.10\u0026#34; # example of ip hostname: \u0026#34;raspberrypi\u0026#34; username: \u0026#34;pi\u0026#34; password: \u0026#34;raspberrypi\u0026#34; - ip: \u0026#34;10.11.11.11\u0026#34; # another example using ssh key hostname: \u0026#34;old_server\u0026#34; username: \u0026#34;ubuntu\u0026#34; ssh_key_path: \u0026#34;BenchPilotSDK/conf/ssh_keys/ssh_key.pem\u0026#34; proxies: # if your device is placed behind a proxy you should also include these http_proxy: \u0026#34;http://example.proxy.com:8080/\u0026#34; https_proxy: \u0026#34;https://example.proxy.com:8080/\u0026#34; .. ** Please keep in mind that every hostname and ip you declare needs to be accessible by the node you will run the BenchPilot client on.\nDefining your Experiments # After defining our cluster, our final step before starting the benchmarking process is to define our experiments! All you need to is define them in a yaml file under /BenchPilotSDK/conf/ using the BenchPilot Model.\nThe BenchPilot model is composed with experiments, where each experiments consists of workload descriptions.\nFor each experiment, you have to define the following:\nrecord_name, so that you can later on retrieve monitoring metrics based on it, number of repetitions that the experiment will be conducted. the duration of the whole experiment. On the other hand, every workload, needs to have the following descriptions:\nname, which will be selected from the supported workload list, e.g. \u0026ldquo;marketing-campaign\u0026rdquo;. cluster, which consists the list of resources that will be used as workers to deploy the workload. orchestrator, this is optional. One can define the underlying orchestrator that will be used for the deployment, the default is docker swarm. duration: This parameter specifies the length of time that a particular workload will be deployed. It is important that this duration exceeds the duration of the experiment. Alternatively, you can simply enter \u0026ldquo;default\u0026rdquo; if preferred. specific workload parameters: you can find more information regarding the parameters here. An example of the /BenchPilotSDK/conf/demo.yaml can be found below:\nidle_between_experiments: \u0026#34;2m\u0026#34; experiments: - experiment: record_name: \u0026#34;mlStorm_old_server\u0026#34; # name must be \u0026lt; 63 characters repetition: 1 duration: \u0026#34;default\u0026#34; workloads: - name: \u0026#34;mlperf\u0026#34; cluster: [\u0026#34;old_server\u0026#34;] # workers\u0026#39; hostnames orchestrator: \u0026#34;swarm\u0026#34; duration: \u0026#34;8m\u0026#34; parameters: dataset_folder: \u0026#34;imagenet2012\u0026#34; model_file: \u0026#34;resnet50_v1.onnx\u0026#34; profile: \u0026#34;resnet50-onnxruntime\u0026#34; data_volume_path: \u0026#34;/mlperf/data\u0026#34; model_volume_path: \u0026#34;/mlperf/model\u0026#34; output_volume_path: \u0026#34;/mlperf/output\u0026#34; worker_threads: 12 - name: \u0026#34;marketing-campaign\u0026#34; cluster: [\u0026#34;old_server\u0026#34;] # workers\u0026#39; hostnames duration: \u0026#34;8m\u0026#34; parameters: num_of_campaigns: 100000 capacity_per_window: 10000 kafka_event_count: 100000000 time_divisor: 10000 workload_tuples_per_second_emission: 1000000 engine: name: \u0026#34;storm\u0026#34; parameters: ackers: 2 executors_per_node: [ 4 ] ui_port: \u0026#34;8080\u0026#34; - experiment: record_name: \u0026#34;mdb_scpu_rpi\u0026#34; repetition: 1 duration: \u0026#34;default\u0026#34; workloads: - name: \u0026#34;database\u0026#34; duration: \u0026#34;20m\u0026#34; cluster: [ \u0026#34;raspberrypi\u0026#34; ] # workers\u0026#39; hostnames parameters: db: \u0026#34;mongodb\u0026#34; threads: 12 - name: \u0026#34;simple\u0026#34; cluster: [ \u0026#34;raspberrypi\u0026#34; ] # workers\u0026#39; hostnames parameters: service: \u0026#34;stress\u0026#34; options: - \u0026#34;--cpu\u0026#34;: \u0026#34;4\u0026#34; .. ** BenchPilot will run the experiments with the order you described them.\n"},{"id":3,"href":"/BenchPilot/docs/workloads/","title":"Workloads","section":"Docs","content":" Workloads # As for now BenchPilot only supports the following containerized workloads:\nName Description Specific Configuration Parameters marketing-campaign A streaming distributed workload that features an application as a data processing pipeline with multiple and diverse steps that emulate insight extraction from marketing campaigns. The workload utilizes technologies such as Kafka and Redis. campaigns, which is the number of campaigns, the default number is 1000.tuples_per_second, the number of emitted tuples per second, the default is 10000. kafka_event_count, the number of generated and published events on kafka, the default is 1000000. maximize_data, this attribute is used to automatically maximize the data that are critically affecting the workload\u0026rsquo;s performance, the input that the user can put is in the format of x10, x100, etc. mlperf An inference workload, that includes tasks such as image classification and object recognition. dataset_folder, which is the dataset folder, the one we have been using for our experiments is the imagenet2012, model_file, the model file that the mlperf will use for inferencing the images, for e.g. resnet50_v1.pbprofile, the mlperf\u0026rsquo;s profile, e.g. resnet50-tf data_volume_path, the path that will be used to volume the data from, this is done as to not avoid creating huge workload images, and due to having easier configuration db A nosql database workload that keeps executing CRUD operations (Create, Read, Update and Delete). db, the database that will be used as the underlying once, for now, only mongodb is supported.threads, the number of threads to be used for executing the operations. The default number of threads is 1.record_count, the number of records that will be loaded as a starting dataset into the database. The default number is 2500000. operation_count, the number of operations that will be executed during the workload - this can affect the time that the experiment will need to finish. The default number is 2500000. read_proportion, this is a float number, that represents that percentage of read operations to be executed during the benchmark, the default is 0.5 update_proportion, this is a float number, that represents that percentage of update operations to be executed during the benchmark, the default is 0.5 scan_proportion, the percentage of read operations to be executed during the experiment. The default is 0. insert_proportion, the proportion of insert operations to be executed. The default is 0. request_distribution, the distribution of the pattern of data access. The default is zipfian. simple This workload represents simple stressors that target a specific resource to stress. Underneath uses the linux command stress or IPerf3. service, which can be either iperf3 or stress options, here you need to define the options as you would insert them while using the iperf3 or stress command. For e.g. for iperf3, the options should be \u0026ldquo;-c\u0026rdquo; to set the client\u0026rsquo;s ip, or \u0026ldquo;-s\u0026rdquo; for the server ip, and \u0026ldquo;-p\u0026rdquo; for setting the targeted port. In case, of selecting stress, the options could be for example \u0026ldquo;\u0026ndash;vm\u0026rdquo;: \u0026ldquo;12\u0026rdquo;, and \u0026ldquo;\u0026ndash;vm-bytes\u0026rdquo;: \u0026ldquo;1024M\u0026rdquo;. It\u0026rsquo;s important to note that BenchPilot can be easily extended to add new workloads.\nFor extending BenchPilot check this section out.\nDetailed Workload Information # Streaming Analytic Workload / Marketing-Campaign # For this workload, we have employed the widely known Yahoo Streaming Benchmark, which is designed to simulate a data processing pipeline for extracting insights from marketing campaigns. the pipeline executed on the edge device includes steps such as receiving advertising traffic data, filtering the data, removing any unnecessary values, combining the data with existing information from a key-value store, and storing the final results. All data produced by a data generator is pushed and extracted through a message queue (Apache Kafka), while intermediate data and final results are stored in an in-memory database (Redis). This workload can be executed using any of the following distributed streaming processing engines: Apache Storm, Flink, Spark.\nCollected Performance Metrics # For evaluating the performance of this application, we extract the following measurements from the benchmarking log files:\nMetric Description # of Tuples The total number of tuples processed during execution Latency The total application latency, measured in ms, based on the statistics provided by the selected underlying processing engine for each deployed task Distributed Processing Engine Parameters # As mentioned, this workload can be executed using any of the following streaming distributed processing engines: Apache Storm, Flink or Spark.\nFor each of those engine, the user can alter/define the following attributes:\nEngine Storm Flink Spark Parameters partitionsackers partitionsbuffer_timeoutcheckpoint_interval partitionsbatchtimeexecutor_coresexecutor_memory Machine Learning Inference Workload / MLPerf # We use MLPerf, a benchmark for machine learning training and inference, to assess the performance of our inference system. Currently, our focus is on two MLPerf tasks:\nImage Classification: This task uses the ImageNet 2012 dataset (resized to 224x224) and measures Top-1 accuracy. MLPerf provides two model options: ResNet-50 v1.5, which excels in image classification, and RetinaNet, which is effective in object detection and bounding box prediction. Object Detection: This task identifies and classifies objects within images, locating them with bounding boxes. MLPerf uses two model configurations: a smaller, 300x300 model for low-resolution tasks (e.g., mobile devices) and a larger, high-resolution model (1.44 MP). Performance is measured by mean average precision (mAP). The SSD model with a ResNet-34 backbone is the default for this task. Additionally, we have extended MLPerf by adding network-serving capabilities to measure the impact of network overhead on inference. Our setup includes:\nA lightweight server that loads models and provides a RESTful API. A workload generator that streams images to the server one-by-one (‚Äústreaming mode‚Äù), contrasting with MLPerf\u0026rsquo;s standard local loading (‚Äúdefault mode‚Äù). For this workload, it is possible to flexibly and easily configure the dataset, latency, batch size, workload duration, thread count, and inference framework (ONNX, NCNN, TensorFlow, or PyTorch).\nCollected Performance Metrics # For evaluating the performance of this application, we extract the following measurements from the benchmarking log files:\nMetric Description Accuracy % The model's accuracy that was measured during the benchmarking period Average and/or Total Queries per Second The # of queries that were executing during the experiment - each query represents the processing a batch of images Mean Latency The application's mean latency, measured in ms NoSQL Database Workload # Through the Yahoo! Cloud Serving Benchmark (YCSB) workload, one can evaluate NoSQL databases like MongoDB, Redis, Cassandra, and Elasticsearch under heavy load. YCSB tests basic operations‚Äîread, update, and insert‚Äîon each database using defined operation rates across an experiment‚Äôs duration. Currently, BenchPilot only supports MongoDB as the underlying database. However, it can be easily adapted to the rest of the databases by containerizing them.\nAdditionally, YCSB supports three workload distributions:\nZipfian: Prioritizes frequently accessed items. Latest: Similar to Zipfian but focuses on recently inserted records. Uniform: Accesses items randomly. For this benchmark, users can adjust various parameters, including the number of records, total operations, load distribution, operation rate, and experiment duration. It also supports multiple threads for increased database load through asynchronous operations.\nCollected Performance Metrics # For evaluating the performance of this application, we can extract the following measurements from the log files:\nMetric Description Count Total number of operations per second for each minute of the experiment Min Min number of operations per second for each minute of the experiment Max Max number of operations per second for each minute of the experiment Average Average number of operations per second for each minute of the experiment "},{"id":4,"href":"/BenchPilot/docs/monitoring/","title":"Monitoring","section":"Docs","content":" BenchPilot Monitoring System # BenchPilot Monitoring divides its services on the Control Plane, where BenchPilot Client and core monitoring services will run on, and its workers, where the benchmarking will happen.\nOn the Control Plane, BenchPilot reuses the following existing projects:\nConsul, for service registration Prometheus, for keeping metrics Influxdb, for long-term storing metrics On each Worker device, BenchPilot uses Netdata for capturing its metrics, and meross smart plugs for retrieving energy consumption. You can use any smart plug you wish for capturing energy consumption by exposing its measures to Netdata. Additionally, since we\u0026rsquo;ve been recently experimenting on co-located scenarios, we decided to expose cadvisor metrics to netdata, as to retrieve metrics per docker container (benchmark service).\nYou can find everything that you might need for the the monitoring stack in our repository, under the monitoring folder.\nSetup Monitoring System # First of all, you need to download or clone our GitHub Repository.\nInstall Docker \u0026amp; Docker Compose # If you haven\u0026rsquo;t installed docker and docker-compose on your devices yet (control plane \u0026amp; workers), just execute the following command on each one of them:\nsh install-docker.sh Start Control-Plane Services # When you have docker and docker-compose installed, all you need to run on the Control Plane is the following command:\ndocker-compose up -f docker-compose-monitoring.yaml Don\u0026rsquo;t forget to replace the environment variables however you would wish to (e.g. \u0026ldquo;${database_name}\u0026rdquo;)\nStart Worker Services # On each Worker you can start and setup Netdata by just running:\ndocker-compose up -f docker-compose.yaml If you will not use any kind smart plugs, just comment-out the smart plug docker service, otherwise, please update (i) your meross account\u0026rsquo;s information and (ii) the smart plug\u0026rsquo;s unique name/number.\nChanging smart plug configuration # There are two things needed for this process:\nFirst you should remove/change the \u0026ldquo;smart-plug\u0026rdquo; service from docker-compose.yaml Update the netdata/prometheus.conf. You should update accordingly the \u0026ldquo;smart_plug\u0026rdquo; configuration, which is defined in the end of the \u0026ldquo;prometheus.conf\u0026rdquo;. This setup is responsible for exposing the power consumption measurements to netdata. Register Worker nodes to Consul # After you have started the worker services, on each worker, enter the Consul folder and execute the following command:\nsh register_to_consul.sh Please, don\u0026rsquo;t forget to replace the IPs and ports in the script(Consul Ip \u0026amp; Port, worker device IP and netdata port)\n"},{"id":5,"href":"/BenchPilot/docs/experiment-analysis/","title":"Post-Experiment Analysis","section":"Docs","content":" Post-Experiment Analysis # After running all of our experiments, it\u0026rsquo;s time to view our results!\nJupyter # For your ease of accessing and processing the results, we used Jupyter Notebook.\nPrometheus Client # We have created under /BenchpilotSDK/controllers package a postExperimentController class. You can export the collected utilization metrics from the prometheus using the following code:\nfrom BenchPilotSDK.controllers.postExperimentController import PostExperimentController postExpController = PostExperimentController() exp_name = \u0026#34;Your given record_name of your experiment\u0026#34; metadata_json_file = \u0026#34;/BenchPilotSDK/experiments/\u0026#34; + exp_name + \u0026#34;.json\u0026#34; exp_file = \u0026#34;/BenchPilotSDK/conf/\u0026#34; + exp_name + \u0026#34;.yaml\u0026#34; postExpController.load_benchmark_meta(metadata_json_file) experiments = postExpController.get_available_workloads_from_metadata() exported_benchmarks = [] for experiment in experiments: exported_benchmarks.append({experiment: postExpController.get_benchmark_metrics(experiment, export_results_to_csv=True)}) Please remember to use the methods \u0026ldquo;assign_prometheus_prefix\u0026rdquo; and \u0026ldquo;assign_prometheus_suffix\u0026rdquo; in order to assign your prometheus\u0026rsquo; prefixes and suffixes.\nFor more information about Jupyter, please visit their website.\n"},{"id":6,"href":"/BenchPilot/docs/exteding-framework/","title":"Exteding BenchPilot","section":"Docs","content":" Extending BenchPilot # This section describes all of the steps you need to take in order to extend BenchPilot for supporting more workloads!\nDockerize Workload # The first step to extend BenchPiot, is to create the necessary docker images. In general BenchPilot utilizes the idea of having a controller node (which BenchPilot\u0026rsquo;s client and other core services will reside on), and the workers, which will be the system under test. Having this scheme in mind, you need to dockerize your workload, and to divide it into images that will reside on your controller node, and another image which will be deployed on the workers.\nAdding New Services # After creating the latter images, you should add under the /BenchPilotSDK/services the new service. That class should derive its properties from the BenchPilot\u0026rsquo;s abstract service object. Keep in mind that for every docker image you created for your workload, you should declare it as a different service.\nFor each service it is important to declare the following:\ndocker image, either an already existing one, or you have to create it on your own hostname, we use the same one as the service name usually image tag, in cases of having different images for arm infrastructures you can define it using the \u0026ldquo;image_arm_tag\u0026rdquo; attribute. ports, needed ports environment, needed environment variables / configurations service log, the log that the service prints when is up and running Depends On, here you should add the service name that it\u0026rsquo;s important to start before the one you just created Command, in case if it needs to execute a specific command when the service starts Proxy, a simple \u0026ldquo;True\u0026rdquo; / \u0026ldquo;False\u0026rdquo; definition, whether it will reside on a device that passes through proxy needs_placement, again, \u0026ldquo;True\u0026rdquo; if it should reside on a worker, \u0026ldquo;False\u0026rdquo; if it\u0026rsquo;s a core service and will reside on the manager node To configure the environment, ports, volumes, and images of the service, you should call the appropriate methods rather than directly assigning them to parameters. This approach simplifies the process by eliminating the need to understand the exact initialization details of these parameters.\nBelow you can see a service example:\nfrom BenchPilotSDK.services.service import Service class Redis(Service): \u0026#34;\u0026#34;\u0026#34; This class represents the redis docker service \u0026#34;\u0026#34;\u0026#34; def __init__(self): Service.__init__(self) self.hostname = \u0026#34;redis\u0026#34; self.assign_image(image_name=\u0026#34;bitnami/redis\u0026#34;, image_tag=\u0026#34;6.0.10\u0026#34;) self.add_environment(\u0026#34;ALLOW_EMPTY_PASSWORD\u0026#34;, \u0026#34;yes\u0026#34;) self.service_started_log = \u0026#34;Ready to accept connections\u0026#34; ** Before adding new services, check first if it already exists.\nAdding New Workload # After adding all of your workload\u0026rsquo;s services, you should create a new workload class as well, under the /BenchPilotSDK/workloads. This particular class will inherit its behavior from the \u0026ldquo;workload\u0026rdquo; class. In that class you should add in the \u0026ldquo;services list\u0026rdquo; all the services you need.\nIn the following block you can find a Workload example:\nfrom abc import ABC import BenchPilotSDK.utils.benchpilotProcessor as bp from BenchPilotSDK.utils.exceptions import BenchExperimentInvalidException from BenchPilotSDK.workloads.workload import Workload from BenchPilotSDK.services.materializedServices.stress import Stress class Simple(Workload, ABC): \u0026#34;\u0026#34;\u0026#34; This class represents the Simple Workload, it just creates a specific simple workload. \u0026#34;\u0026#34;\u0026#34; def __init__(self, **workload_definition): super().__init__(**workload_definition) bp.check_required_parameters(\u0026#39;workload \u0026gt; parameters\u0026#39;, [\u0026#34;service\u0026#34;], workload_definition[\u0026#34;parameters\u0026#34;]) service = self.parameters[\u0026#34;service\u0026#34;] options = {} if not \u0026#34;options\u0026#34; in self.parameters else self.parameters[\u0026#34;options\u0026#34;] service = Stress(options) ... Adding a new SDPE Workload # In case of adding a new Streaming Distributed - based workload you don\u0026rsquo;t need to add the engines, you only need to inherit from the SDPEWorkload class, and add the rest of the services, like the example below:\nimport inspect from abc import ABC from dataclasses import dataclass, asdict from BenchPilotSDK.workloads.materializedWorkloads.sdpeWorkload import SDPEWorkload from BenchPilotSDK.services.materializedServices.kafka import Kafka from BenchPilotSDK.services.materializedServices.redis import Redis from BenchPilotSDK.services.materializedServices.zookeeper import Zookeeper class MarketingCampaign(SDPEWorkload, ABC): \u0026#34;\u0026#34;\u0026#34; This class represents Yahoo Streaming Benchmark, it holds all the extra needed services. - by extra we mean the services that are not DSPEs \u0026#34;\u0026#34;\u0026#34; @dataclass class Parameters: num_of_campaigns: int = 1000 ... @classmethod def from_dict(cls, env): return cls(**{ k: v for k, v in env.items() if k in inspect.signature(cls).parameters }) def __post_init__(self): .. def __init__(self, **workload_definition): super().__init__(**workload_definition) self.parameters.update(asdict(self.Parameters.from_dict(workload_definition))) self.add_service(Zookeeper()) self.add_service(Kafka(len(self.cluster), self.manager_ip)) self.add_service(Redis()) "}]