<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on BenchPilot</title>
    <link>http://localhost:1313/BenchPilot/docs/</link>
    <description>Recent content in Docs on BenchPilot</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/BenchPilot/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Getting Started</title>
      <link>http://localhost:1313/BenchPilot/docs/getting-started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/getting-started/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bbenchpilotstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;BenchPilot&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bbenchpilotstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;BenchPilot: Repeatable &amp;amp; Reproducible Benchmarking for Edge Micro-DCs&lt;/p&gt;&#xA;&lt;p&gt;BenchPilot is a modular and highly customizable benchmarking framework for edge micro-DCs.&#xA;BenchPilot provides a high-level declarative model for describing experiment testbeds and scenarios that automates the benchmarking process using various workloads. The latter enables users to focus on performance analysis instead of dealing with the complex and time-consuming setup. BenchPilot instantiates the underlying cluster, performs repeatable experimentation, and provides a unified monitoring stack in heterogeneous Micro-DCs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installation</title>
      <link>http://localhost:1313/BenchPilot/docs/installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/installation/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bgithub-repositorystrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;GitHub Repository&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bgithub-repositorystrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Visit our &lt;a href=&#34;https://github.com/UCY-LINC-LAB/BenchPilot&#34;&gt; Github Repository &lt;/a&gt; to download or fork BenchPilot!&lt;/p&gt;&#xA;&lt;h1 id=&#34;strong-stylecolor-40897bdockerhubstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;DockerHub&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bdockerhubstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;All of our Docker images are uploaded on our &lt;a href=&#34;https://hub.docker.com/r/benchpilot/benchpilot&#34;&gt; DockerHub Repository&lt;/a&gt;!&lt;/p&gt;&#xA;&lt;h1 id=&#34;strong-stylecolor-40897bbenchpilot-bootstrappingstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;BenchPilot Bootstrapping&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bbenchpilot-bootstrappingstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;install-docker--docker-compose&#34;&gt;&#xA;  Install Docker &amp;amp; Docker Compose&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#install-docker--docker-compose&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;In the &amp;lsquo;Getting Started&amp;rsquo; section we learned how BenchPilot is structured. In order to use the BenchPilot client you need to have installed docker &amp;amp; docker-compose. In our GitHub Repository, under the &lt;em&gt;/utils&lt;/em&gt; folder we have prepared for you a script to automatically download it, so all you need to run is &amp;ldquo;&lt;strong&gt;&lt;code style=&#34;color: #40897B&#34;&gt;sh install-docker.sh&lt;/code&gt;&lt;/strong&gt;&amp;rdquo;, which is under the &lt;i&gt;&lt;code&gt;monitoring&lt;/code&gt;&lt;/i&gt; folder.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Experiments</title>
      <link>http://localhost:1313/BenchPilot/docs/experiments/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/experiments/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bexperimentsstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;Experiments&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bexperimentsstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;Before starting the benchmarking process, you need to define (i) &lt;strong style=&#34;color: #40897B&#34;&gt;the cluster&lt;/strong&gt; under test, and (ii) &lt;strong style=&#34;color: #40897B&#34;&gt;the experiments&lt;/strong&gt; you want to perform.&lt;/p&gt;&#xA;&lt;h2 id=&#34;defining-your-cluster&#34;&gt;&#xA;  Defining your Cluster&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#defining-your-cluster&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;By defining you cluster, Benchpilot removes the effort of you needing to download docker, docker compose and every docker image you may need for your benchmarking on your worker devices. All you need to do is define your cluster inside the &lt;em&gt;/BenchPilotSDK/conf/bench-cluster.yaml&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Workloads</title>
      <link>http://localhost:1313/BenchPilot/docs/workloads/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/workloads/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bworkloadsstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;Workloads&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bworkloadsstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;As for now BenchPilot only supports the following containerized workloads:&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Name&lt;/th&gt;&#xA;          &lt;th&gt;Description&lt;/th&gt;&#xA;          &lt;th&gt;Specific Configuration Parameters&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;span style=&#34;color: #40897B&#34;&gt;&lt;a href=&#34;#ysb&#34;&gt;marketing-campaign&lt;/a&gt;&lt;/span&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A streaming distributed workload that features an application as a data processing pipeline with multiple and diverse steps that emulate insight extraction from marketing campaigns. The workload utilizes technologies such as &lt;a href=&#34;https://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt; and &lt;a href=&#34;https://redis.io/&#34;&gt;Redis&lt;/a&gt;.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;campaigns&lt;/i&gt;, which is the number of campaigns, the default number is 1000.&lt;/li&gt;&lt;li&gt;&lt;i&gt;tuples_per_second&lt;/i&gt;, the number of emitted tuples per second, the default is 10000.&lt;/li&gt; &lt;li&gt;&lt;i&gt;kafka_event_count&lt;/i&gt;, the number of generated and published events on kafka, the default is 1000000.&lt;/li&gt; &lt;li&gt;&lt;i&gt;maximize_data&lt;/i&gt;, this attribute is used to automatically maximize the data that are critically affecting the workload&amp;rsquo;s performance, the input that the user can put is in the format of x10, x100, etc.&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;span style=&#34;color: #40897B&#34;&gt;&lt;a href=&#34;#mlperf&#34;&gt;mlperf&lt;/a&gt;&lt;/span&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An inference workload, that includes tasks such as image classification and object recognition.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;dataset_folder&lt;/i&gt;, which is the dataset folder, the one we have been using for our experiments is the imagenet2012,&lt;/li&gt; &lt;li&gt;&lt;i&gt;model_file&lt;/i&gt;, the model file that the mlperf will use for inferencing the images, for e.g. resnet50_v1.pb&lt;/li&gt;&lt;li&gt;&lt;i&gt;profile&lt;/i&gt;, the mlperf&amp;rsquo;s profile, e.g. resnet50-tf&lt;/li&gt; &lt;li&gt;&lt;i&gt;data_volume_path&lt;/i&gt;, the path that will be used to volume the data from, this is done as to not avoid creating huge workload images, and due to having easier configuration&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;span style=&#34;color: #40897B&#34;&gt;&lt;a href=&#34;#ycsb&#34;&gt;db&lt;/a&gt;&lt;/span&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A nosql database workload that keeps executing CRUD operations (Create, Read, Update and Delete).&lt;/td&gt;&#xA;          &lt;td&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;db&lt;/i&gt;, the database that will be used as the underlying once, for now, only mongodb is supported.&lt;/li&gt;&lt;li&gt;&lt;i&gt;threads&lt;/i&gt;, the number of threads to be used for executing the operations. The default number of threads is 1.&lt;/li&gt;&lt;li&gt;&lt;i&gt;record_count&lt;/i&gt;, the number of records that will be loaded as a starting dataset into the database. The default number is 2500000.&lt;/li&gt; &lt;li&gt;&lt;i&gt;operation_count&lt;/i&gt;, the number of operations that will be executed during the workload - this can affect the time that the experiment will need to finish. The default number is 2500000.&lt;/li&gt; &lt;li&gt;&lt;i&gt;read_proportion&lt;/i&gt;, this is a float number, that represents that percentage of read operations to be executed during the benchmark, the default is 0.5&lt;/li&gt;  &lt;li&gt;&lt;i&gt;update_proportion&lt;/i&gt;, this is a float number, that represents that percentage of update operations to be executed during the benchmark, the default is 0.5&lt;/li&gt;  &lt;li&gt;&lt;i&gt;scan_proportion&lt;/i&gt;, the percentage of read operations to be executed during the experiment. The default is 0.&lt;/li&gt; &lt;li&gt;&lt;i&gt;insert_proportion&lt;/i&gt;, the proportion of insert operations to be executed. The default is 0.&lt;/li&gt; &lt;li&gt;&lt;i&gt;request_distribution&lt;/i&gt;, the distribution of the pattern of data access. The default is zipfian.&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;span style=&#34;color: #40897B&#34;&gt;simple&lt;/span&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This workload represents simple stressors that target a specific resource to stress. Underneath uses the linux command &lt;a href=&#34;https://linux.die.net/man/1/stress&#34;&gt;stress&lt;/a&gt; or &lt;a href=&#34;https://man.archlinux.org/man/iperf3.1.en&#34;&gt;IPerf3&lt;/a&gt;.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;service&lt;/i&gt;, which can be either iperf3 or stress &lt;/li&gt;&lt;li&gt;&lt;i&gt;options&lt;/i&gt;, here you need to define the options as you would insert them while using the iperf3 or stress command. For e.g. for iperf3, the options should be &amp;ldquo;-c&amp;rdquo; to set the client&amp;rsquo;s ip, or &amp;ldquo;-s&amp;rdquo; for the server ip, and &amp;ldquo;-p&amp;rdquo; for setting the targeted port. In case, of selecting stress, the options could be for example &amp;ldquo;&amp;ndash;vm&amp;rdquo;: &amp;ldquo;12&amp;rdquo;, and &amp;ldquo;&amp;ndash;vm-bytes&amp;rdquo;: &amp;ldquo;1024M&amp;rdquo;.&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;strong&gt;It&amp;rsquo;s important to note that BenchPilot can be easily extended to add new workloads.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Monitoring</title>
      <link>http://localhost:1313/BenchPilot/docs/monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/monitoring/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bbenchpilot-monitoring-systemstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;BenchPilot Monitoring System&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bbenchpilot-monitoring-systemstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;BenchPilot Monitoring divides its services on the &lt;strong&gt;Control Plane&lt;/strong&gt;, where BenchPilot Client and core monitoring services will run on, and its &lt;strong&gt;workers&lt;/strong&gt;, where the benchmarking will happen.&lt;/p&gt;&#xA;&lt;p&gt;On the &lt;strong&gt;Control Plane&lt;/strong&gt;, BenchPilot reuses the following existing projects:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://www.consul.io/&#34;&gt;Consul&lt;/a&gt;&lt;/em&gt;, for service registration&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://prometheus.io/&#34;&gt;Prometheus&lt;/a&gt;&lt;/em&gt;, for keeping metrics&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;&lt;a href=&#34;https://www.influxdata.com/&#34;&gt;Influxdb&lt;/a&gt;&lt;/em&gt;, for long-term storing metrics&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;On each &lt;strong&gt;Worker&lt;/strong&gt; device, BenchPilot uses &lt;em&gt;&lt;a href=&#34;https://www.netdata.cloud/&#34;&gt;Netdata&lt;/a&gt;&lt;/em&gt; for capturing its metrics, and &lt;em&gt;&lt;a href=&#34;https://www.meross.com/en-gc/product&#34;&gt;meross smart plugs&lt;/a&gt;&lt;/em&gt; for retrieving energy consumption. You can use any smart plug you wish for capturing energy consumption by exposing its measures to Netdata. Additionally, since we&amp;rsquo;ve been recently experimenting on co-located scenarios, we decided to expose &lt;em&gt;&lt;a href=&#34;https://github.com/google/cadvisor&#34;&gt;cadvisor&lt;/a&gt;&lt;/em&gt; metrics to netdata, as to retrieve metrics per docker container (benchmark service).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Post-Experiment Analysis</title>
      <link>http://localhost:1313/BenchPilot/docs/experiment-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/experiment-analysis/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bpost-experiment-analysisstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;Post-Experiment Analysis&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bpost-experiment-analysisstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;After running all of our experiments, it&amp;rsquo;s time to view our results!&lt;/p&gt;&#xA;&lt;h2 id=&#34;jupyter&#34;&gt;&#xA;  Jupyter&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#jupyter&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;For your ease of accessing and processing the results, we used Jupyter Notebook.&lt;/p&gt;&#xA;&lt;h2 id=&#34;prometheus-client&#34;&gt;&#xA;  Prometheus Client&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#prometheus-client&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We have created under /BenchpilotSDK/controllers package a postExperimentController class. You can export the collected utilization metrics from the prometheus using the following code:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; BenchPilotSDK.controllers.postExperimentController &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; PostExperimentController&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;postExpController &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PostExperimentController()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;exp_name &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Your given record_name of your experiment&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;metadata_json_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/BenchPilotSDK/experiments/&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; exp_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.json&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;exp_file &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;/BenchPilotSDK/conf/&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; exp_name &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.yaml&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;postExpController&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_benchmark_meta(metadata_json_file)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;experiments &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; postExpController&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_available_workloads_from_metadata()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;exported_benchmarks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; experiment &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; experiments:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    exported_benchmarks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append({experiment: postExpController&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_benchmark_metrics(experiment, export_results_to_csv&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)})&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Please remember to use the methods &amp;ldquo;assign_prometheus_prefix&amp;rdquo; and &amp;ldquo;assign_prometheus_suffix&amp;rdquo; in order to assign your prometheus&amp;rsquo; prefixes and suffixes.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exteding BenchPilot</title>
      <link>http://localhost:1313/BenchPilot/docs/exteding-framework/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/BenchPilot/docs/exteding-framework/</guid>
      <description>&lt;h1 id=&#34;strong-stylecolor-40897bextending-benchpilotstrong&#34;&gt;&#xA;  &lt;strong style=&#34;color: #40897B&#34;&gt;Extending BenchPilot&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#strong-stylecolor-40897bextending-benchpilotstrong&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;This section describes all of the steps you need to take in order to extend BenchPilot for supporting more workloads!&lt;/p&gt;&#xA;&lt;h2 id=&#34;dockerize-workload&#34;&gt;&#xA;  Dockerize Workload&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#dockerize-workload&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;The first step to extend BenchPiot, is to create the necessary docker images. In general BenchPilot utilizes the idea of having a controller node (which BenchPilot&amp;rsquo;s client and other core services will reside on), and the workers, which will be the system under test. Having this scheme in mind, you need to dockerize your workload, and to divide it into images that will reside on your controller node, and another image which will be deployed on the workers.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
